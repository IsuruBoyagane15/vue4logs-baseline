{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "vue4logs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsuruBoyagane15/vue4logs-baseline/blob/master/vue4logs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV6ChVypV0fd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lGQathzq4YG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_directory = \"Vue4Logs\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjXc2iL781Rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/gdrive/My Drive/{project_directory}/Thaler2017"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbDpjTOpAKoF",
        "colab_type": "text"
      },
      "source": [
        "# Use legacy dependancies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXkaR8FsN6hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorflow==1.0.1\n",
        "!pip3 install nltk==3.2.5\n",
        "!pip3 install numpy==1.17.0\n",
        "!pip3 install matplotlib==2.0.2\n",
        "!pip3 install scipy==0.19.1\n",
        "!pip3 install scikit-learn==0.19.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thB18KVgZUri",
        "colab_type": "text"
      },
      "source": [
        "# SPECIFY dataset name, number (add entry to all_experiments.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX4r2bgywEK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = \"apache\"\n",
        "dataset_number = 18\n",
        "experiment_type = 'ae_c_2_epochs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7SD2BXhstrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change dataset/main_dataset_folder name in fiel paths\n",
        "!cp /content/gdrive/My\\ Drive/{project_directory}/Datasets_TB/final_training_log_files/{dataset}/{dataset}.log data\n",
        "!cp /content/gdrive/My\\ Drive/{project_directory}/Datasets_TB/ground_truth/{dataset}/{dataset}.log data/test\n",
        "!cp /content/gdrive/My\\ Drive/{project_directory}/Datasets_TB/ids_files/{dataset}/{dataset}.ids data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flhZC7QqGund",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# display ipython notebook full width\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
        "# autoreloading https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKA_QJwndovT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from library.all_imports import * \n",
        "from library.helpers import save_to_json, load_from_json, save_to_csv, create_if_not_exists, get_N_HexCol, multiprocess_file\n",
        "from library.plotting import plot\n",
        "\n",
        "assert tf.__version__==\"1.0.1\" # the tensorflow library we used \n",
        "tf.set_random_seed(0)\n",
        "np.random.seed(0) # fix random seed for reproducability\n",
        "# tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo8XcndIGunp",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ifniE9lGunq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from library.all_experiments import * # experiments are defined here\n",
        "\n",
        "def lib_name(exp_nr):\n",
        "    if exp_nr in EXPERIMENT_LIB_MAPPING:\n",
        "        return \"data_generation.%s\"%EXPERIMENT_LIB_MAPPING[exp_nr]\n",
        "    else:\n",
        "        return \"data_generation.%s\"%ALL_EXPERIMENTS[exp_nr] \n",
        "    \n",
        "experiment_nr = dataset_number\n",
        "EXPERIMENT_ID = ALL_EXPERIMENTS[experiment_nr] # choose data - it will be automatically generated\n",
        "print(\"Running experiment: %s\"%EXPERIMENT_ID)\n",
        "EXPERIMENT_SPLIT_TOKEN = SPLIT_TOKEN[experiment_nr] if (experiment_nr in SPLIT_TOKEN.keys()) else SPLIT_TOKEN[\"default\"]\n",
        "\n",
        "unknown_token = g.unknown_token = \"UNKNOWN_TOKEN\"\n",
        "logline_start_token = g.logline_start_token = \"LOG_START\"\n",
        "logline_end_token = g.logline_end_token= \"LOG_END\"\n",
        "pad_token = g.pad_token = \"PAD_TOKEN\"\n",
        "g.vocabulary_max_lines = -1 # -1 means unlimited\n",
        "g.max_line_len = 200\n",
        "\n",
        "# define names\n",
        "run_tag = \"m-pn\"\n",
        "model_name = \"rnn-autoencoder\"\n",
        "\n",
        "# clustering \n",
        "cluster_alg=\"birch\" # alternatives:  birch hierarch dbscan  \n",
        "\n",
        "# create experiment directories\n",
        "result_dir = \"results\"\n",
        "experiment_dir = \"%.2d_%s\"%(experiment_nr,EXPERIMENT_ID)\n",
        "experiment_outdir = join_path(result_dir, experiment_dir ,  now_str )\n",
        "checkpoint_path = join_path(experiment_dir , \"graph\", run_tag)\n",
        "graph_dir = join_path(experiment_outdir,\"graph\",run_tag)\n",
        "\n",
        "create_if_not_exists(checkpoint_path)\n",
        "create_if_not_exists(graph_dir)\n",
        "\n",
        "# data files\n",
        "datafile = g.datafile =  \"data/%s.log\"%EXPERIMENT_ID\n",
        "labels_true_file = \"data/%s.ids\"%EXPERIMENT_ID\n",
        "processed_datafile = join_path(result_dir, experiment_dir,\"%s_log.processed\"%EXPERIMENT_ID)\n",
        "test_data_processed = join_path(result_dir, experiment_dir,\"%s_test_log.processed\"%EXPERIMENT_ID) \n",
        "VOCABULARY_FILE = g.VOCABULARY_FILE = join_path(result_dir, experiment_dir, \"vocabulary.json\")\n",
        "HYPERPARAMETERS_FILE = join_path(experiment_outdir, \"hyperparams.json\")\n",
        "CLUSTERING_RESULTS_FILE = join_path(experiment_outdir, \"clustering_results.csv\")\n",
        "learned_weights_file = join_path(experiment_outdir,\"learned_weights.csv\")\n",
        "DATASET_STATS_FILE = join_path(result_dir, experiment_dir, \"dataset_statistics.json\")                                \n",
        "\n",
        "g.REGENERATE_VOCABULARY_FILES = True    \n",
        "g.REPROCESS_TRAININGS_DATA  = True\n",
        "learn_model = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WevBfqPeGunv",
        "colab_type": "text"
      },
      "source": [
        "# Generate vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pGd5yMMGunv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g.WORD_TO_INDEX_FILE = join_path(result_dir, experiment_dir, \"word_to_index.json\")\n",
        "g.INDEX_TO_WORD_FILE = join_path(result_dir, experiment_dir, \"index_to_word.json\")\n",
        "g.TOKENIZED_LOGLINES_FILE = join_path(result_dir, experiment_dir, \"tokenized_loglines.json\")\n",
        "g.SPLIT_TOKEN = EXPERIMENT_SPLIT_TOKEN\n",
        "\n",
        "# g.SPLIT_TOKEN = ['\"']\n",
        "from library.vocabulary import *\n",
        "print(\"Dataset fully loaded\")       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n02QsVfPGun0",
        "colab_type": "text"
      },
      "source": [
        "# Datset statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcNgkmJLGun1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for w in sorted(word_frequencies.iteritems(), key= lambda x:x[1], reverse=True):\n",
        "del word_frequencies[\"LOG_START\"]\n",
        "del word_frequencies[\"LOG_END\"]\n",
        "\n",
        "words,frequencies = zip(*sorted(word_frequencies.items(), key= lambda x:x[1], reverse=True))\n",
        "print(\"sorted words\")\n",
        "print(words[0:200])\n",
        "\n",
        "total_words = len(words)\n",
        "stratify_parts = 200\n",
        "\n",
        "stratum_length = total_words/stratify_parts\n",
        "\n",
        "indices = []\n",
        "\n",
        "for i in range(stratify_parts):    \n",
        "    strat_start = i* stratum_length\n",
        "    strat_end = (i+1) * stratum_length -1   \n",
        "    new_index = np.random.randint(strat_start, strat_end)\n",
        "#    print(strat_start, strat_end, new_index)\n",
        "    indices.append(new_index)\n",
        "    \n",
        "words = np.array(words)[indices]\n",
        "frequencies = np.array(frequencies)[indices]\n",
        "\n",
        "print(\"Sorted words.\")\n",
        "\n",
        "words = [str(w) for w in words]\n",
        "colors = []\n",
        "for w in words:\n",
        "    if w.isdigit():\n",
        "        colors.append(\"r\")# \"#ffcccc\" light red      \n",
        "    else:\n",
        "        colors.append(\"#ccffcc\") #light green\n",
        "print(\"Defined colors\")\n",
        "        \n",
        "cluster_plot_file = join_path(result_dir,experiment_dir, \"dataset_stats.png\")\n",
        "figure_size=(20,10) \n",
        "fig = plt.figure(figsize=figure_size)\n",
        "\n",
        "index = np.arange(len(words))\n",
        "bar_width = 0.35\n",
        "\n",
        "\n",
        "ax1 = fig.add_subplot(111)\n",
        "ax1.bar(index, frequencies,  color=colors)\n",
        "ax1.set_yscale('log')\n",
        "plt.xticks(index + bar_width / 2, (words), rotation=90, fontsize = 8)\n",
        "plt.savefig(cluster_plot_file)\n",
        "plt.close()\n",
        "\n",
        "Image(filename=cluster_plot_file) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7g3UFmbGun5",
        "colab_type": "text"
      },
      "source": [
        "# Average LogLine Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II-t8x_aGun6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "line_lengths = []\n",
        "for logline in tokenized_loglines: \n",
        "    line_lengths.append(len(logline))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_75YctWGuoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.average(line_lengths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPwbXIQ8GuoE",
        "colab_type": "text"
      },
      "source": [
        "# Process trainingsdata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH07c_6wGuoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the training data\n",
        "if g.REPROCESS_TRAININGS_DATA: \n",
        "    X_train = np.asarray([[word_to_index[w] for w in logline] for logline in tokenized_loglines])\n",
        "    maximum_sequence_length =-1\n",
        "    train_numbers_file = open(processed_datafile,\"w\")\n",
        "    one_percent = len(X_train)/100\n",
        "    for i, logline_as_word_id_sequence in enumerate(X_train):\n",
        "        if i%one_percent==0: print(\"Written line %i\"%i)\n",
        "        #print \",\".join(line)\n",
        "\n",
        "        reversed_seq = list(reversed(logline_as_word_id_sequence))\n",
        "        # add sequence length to example\n",
        "\n",
        "        sequence_length = str(len(logline_as_word_id_sequence))\n",
        "        if len(logline_as_word_id_sequence)>maximum_sequence_length: maximum_sequence_length=len(logline_as_word_id_sequence) # find maximum sequence length\n",
        "        word_id_seq = \",\".join(map(str,logline_as_word_id_sequence)) # encoder input: 1,2,3 \n",
        "        word_id_seq_reversed = \",\".join(map(str,reversed_seq)) # decoder input: 3,2,1 \n",
        "        target_seq = \",\".join(map(str, reversed_seq[1:]+[PAD_ID])) # decoder target: 2,1,PAD \n",
        "\n",
        "        signature_id =  5 # experiment_lib.extract_pattern_id(loglines[i]) -------- put bogus value---------------\n",
        "        assert not signature_id==0,\"Each log line has to be associated to one signature, none for (%s). Check extract_pattern_id method.\"%loglines[i]\n",
        "        # write      \n",
        "        train_numbers_file.write(\"%s|%s|%s|%s|%s\\n\"%(signature_id, sequence_length, word_id_seq,word_id_seq_reversed,target_seq))\n",
        "\n",
        "    train_numbers_file.close()\n",
        "\n",
        "    ###\n",
        "\n",
        "    #### tokenizing test data part\n",
        "    tokenized_test_loglines = []\n",
        "\n",
        "    test_loglines = list(open(\"data/test/%s.log\"%EXPERIMENT_ID, 'r'))\n",
        "    print(\"Loaded %i test_loglines\"%len(test_loglines))\n",
        "    total_lines = len(test_loglines) if g.vocabulary_max_lines==-1 else g.vocabulary_max_lines\n",
        "    print(\"Tokenizing test %i lines... \"%total_lines)\n",
        "    print(\"test_loglines\",len(test_loglines))\n",
        "    \n",
        "    for i, test_logline in enumerate(test_loglines):\n",
        "        \n",
        "        test_logline = test_logline.lower()\n",
        "        \n",
        "        for char in g.SPLIT_TOKEN:\n",
        "            test_logline = test_logline.replace(char, ' ' + char + ' ')\n",
        "        \n",
        "        tokenized_test_logline = test_logline.split(\" \")[0:200] #nltk.word_tokenize(logline)\n",
        "        \n",
        "        tokenized_test_logline = [g.logline_start_token] + tokenized_test_logline + [g.logline_end_token]\n",
        "        \n",
        "        tokenized_test_loglines.append(tokenized_test_logline)\n",
        "\n",
        "        if g.vocabulary_max_lines>0 and i>g.vocabulary_max_lines:\n",
        "            break\n",
        "    \n",
        "    for i, test_logline in enumerate(tokenized_test_loglines):\n",
        "        tokenized_test_loglines[i] = [w if w in word_to_index else g.unknown_token for w in test_logline]\n",
        "\n",
        "    print (\"Tokenized logfile.\")\n",
        "    #### tokeninzing test data part finish\n",
        "\n",
        "    array_to_xtrain = []\n",
        "\n",
        "    X_test = np.asarray([[word_to_index[w] for w in logline] for logline in tokenized_test_loglines])\n",
        "\n",
        "    maximum_sequence_length =-1\n",
        "    test_numbers_file = open(test_data_processed,\"w\")\n",
        "    one_percent = len(X_test)/100\n",
        "\n",
        "    for i, test_logline_as_word_id_sequence in enumerate(X_test):\n",
        "\n",
        "        reversed_seq = list(reversed(test_logline_as_word_id_sequence))\n",
        "        # add sequence length to example\n",
        "\n",
        "        sequence_length = str(len(test_logline_as_word_id_sequence))\n",
        "        if len(test_logline_as_word_id_sequence)>maximum_sequence_length: maximum_sequence_length=len(test_logline_as_word_id_sequence) # find maximum sequence length\n",
        "        word_id_seq = \",\".join(map(str,test_logline_as_word_id_sequence)) # encoder input: 1,2,3 \n",
        "        word_id_seq_reversed = \",\".join(map(str,reversed_seq)) # decoder input: 3,2,1 \n",
        "        target_seq = \",\".join(map(str, reversed_seq[1:]+[PAD_ID])) # decoder target: 2,1,PAD \n",
        "\n",
        "        # signature_id = experiment_lib.extract_pattern_id(loglines[i]) #######\n",
        "        signature_id = 5\n",
        "\n",
        "        assert not signature_id==0,\"Each log line has to be associated to one signature, none for (%s). Check extract_pattern_id method.\"%loglines[i]\n",
        "        # write      \n",
        "        test_numbers_file.write(\"%s|%s|%s|%s|%s\\n\"%(signature_id, sequence_length, word_id_seq,word_id_seq_reversed,target_seq))\n",
        "    test_numbers_file.close()\n",
        "    ###\n",
        "else:\n",
        "    X_train = np.asarray([[word_to_index[w] for w in logline] for logline in tokenized_loglines])\n",
        "    print(\"Trainingsdata has already been processed\")\n",
        "\n",
        "if not os.path.exists(labels_true_file):\n",
        "    os.system(\"python3 create_true_labels.py -en %s\"%EXPERIMENT_ID)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnYfXpSoGuoQ",
        "colab_type": "text"
      },
      "source": [
        "#  Graph Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF4fveTwGuoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TDB save vocabulary file\n",
        "state_size = 256 # size of vector internal of a cell\n",
        "batch_size = 200\n",
        "\n",
        "num_examples_to_visualize = min(10000, len(tokenized_loglines)) # how many dots to show\n",
        "num_examples_to_embed = len(tokenized_test_loglines) #len(tokenized_loglines) -------------changed according to the test set------------\n",
        "\n",
        "dropout_keep_probability = 0.7\n",
        "num_lstm_layers = 1\n",
        "\n",
        "DTYPE=tf.float32\n",
        "num_samples = min(vocabulary_size, 500) # number of samples to draw for sampled softmax\n",
        "max_gradient_norm = 0.5 # to be defined\n",
        "\n",
        "LEARNING_RATE = 0.02\n",
        "learning_rate_decay_factor = 0.95\n",
        "l1_scale= 0.000\n",
        "epochs = 1\n",
        "\n",
        "num_examples = len(X_train)\n",
        "max_steps = int(epochs * (num_examples / batch_size))\n",
        "learning_rate_adjustments = 10 # how many times to apply learning rate decay over all epochs\n",
        "adjust_learning_rate_after_steps = max_steps / learning_rate_adjustments\n",
        "\n",
        "# some tf varioables\n",
        "tf_keep_probabiltiy = tf.constant(dropout_keep_probability) \n",
        "tf_global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "\n",
        "# clustering hierarchy\n",
        "examples_in_hierarchy = 50\n",
        "color_threshhold = 0.2\n",
        "\n",
        "# threshold for vmeasure, homogenity etc.\n",
        "h_threshold = 0.004\n",
        "\n",
        "# save hyperparameters\n",
        "hyperparams = {\n",
        "    \"state_size\":state_size,\n",
        "    \"num_examples_to_visualize\":num_examples_to_visualize,\n",
        "    \"dropout_keep_probability\":dropout_keep_probability,\n",
        "    \"num_lstm_layers\":num_lstm_layers,\n",
        "    \"learning_rate_decay_factor\":learning_rate_decay_factor,\n",
        "    \"batch_size\":batch_size,\n",
        "    \"dtype\":str(DTYPE),\n",
        "    \"num_samples\":num_samples,\n",
        "    \"max_gradient_norm\":max_gradient_norm,\n",
        "    \"learning_rate\":LEARNING_RATE,\n",
        "    \"epochs\":epochs,\n",
        "    \"num_examples\":num_examples,\n",
        "    \"max_steps\":max_steps,\n",
        "    \"examples_in_hierarchy\":examples_in_hierarchy,\n",
        "    \"color_threshhold\":color_threshhold,    \n",
        "    \"h_threshold\":h_threshold,\n",
        "}\n",
        "\n",
        "\n",
        "save_to_json(hyperparams, HYPERPARAMETERS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZsj6BLAGuoW",
        "colab_type": "text"
      },
      "source": [
        "#  Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDLKFm_4GuoW",
        "colab_type": "text"
      },
      "source": [
        "## Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myw6QrUtGuoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = tf.train.exponential_decay(\n",
        "  learning_rate=LEARNING_RATE, \n",
        "  global_step=tf_global_step, # current learning step\n",
        "  decay_steps= adjust_learning_rate_after_steps, # how many steps to train after decaying learning rate      \n",
        "  decay_rate=learning_rate_decay_factor,                \n",
        "  staircase=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fkrhLIpGuob",
        "colab_type": "text"
      },
      "source": [
        "## Input, Output and Target of the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSsl77zAGuoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# inputs, outputs\n",
        "x_e = tf.placeholder(tf.int32, [batch_size, None]) # encoder inputs loglines [batch_size, num_steps]\n",
        "x_d = tf.placeholder(tf.int32, [batch_size, None]) # decoder inputs \n",
        "y_d = tf.placeholder(tf.int32, [batch_size, None]) # reversed loglines [batch_size, num_steps]\n",
        "\n",
        "visualization_embeddings = tf.Variable(np.zeros([num_examples_to_visualize, state_size]) , trainable=False, name=\"VisualizationEmbeddings\", dtype= DTYPE   )\n",
        "\n",
        "word_embeddings = tf.get_variable('word_embeddings', [vocabulary_size, state_size], dtype= DTYPE ) # each row is a dense vector for each word.\n",
        "\n",
        "# Encoder Inputs\n",
        "encoder_inputs = tf.nn.embedding_lookup(word_embeddings, x_e) # [batch_size, max_time, embedding_size]\n",
        "encoder_sequence_lengths = tf.placeholder(tf.int32, [batch_size]) # [batch_size]\n",
        "\n",
        "# Decoder Inputs\n",
        "decoder_inputs = tf.nn.embedding_lookup(word_embeddings, x_d) # need to be defined  [batch_size, max_time, embedding_size]\n",
        "decoder_sequence_lengths = tf.placeholder(tf.int32, [batch_size]) # [batch_size]\n",
        "\n",
        "# Decoder Labels\n",
        "decoder_labels = y_d # this are our target words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zaFdNXUGuoh",
        "colab_type": "text"
      },
      "source": [
        "## LSTM, Dropout Wrapper, MultiRNNCell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEgymrwmGuoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from library.core_rnn_cell_impl import DropoutWrapper as DtypeDropoutWrapper # import v1.1.0 dropout wrapper to support setting DTYPE to half-precision\n",
        "\n",
        "# Define cells\n",
        "with tf.variable_scope(\"encoder_scope\") as encoder_scope:\n",
        "\n",
        "    cell = contrib_rnn.LSTMCell(num_units=state_size, state_is_tuple=True)\n",
        "    cell = DtypeDropoutWrapper(cell=cell, output_keep_prob=tf_keep_probabiltiy, dtype=DTYPE)\n",
        "    cell = contrib_rnn.MultiRNNCell(cells=[cell] * num_lstm_layers, state_is_tuple=True)\n",
        "\n",
        "    encoder_cell = cell # needs to be defined\n",
        "\n",
        "    # encode inputs\n",
        "    encoder_outputs, last_encoder_state = tf.nn.dynamic_rnn(\n",
        "        cell=encoder_cell,\n",
        "        dtype=DTYPE,\n",
        "        sequence_length=encoder_sequence_lengths,\n",
        "        inputs=encoder_inputs,\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4161UKHyGuom",
        "colab_type": "text"
      },
      "source": [
        "## Dynamic RNN decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzVTh1h8Guoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.variable_scope(\"decoder_scope\") as decoder_scope:\n",
        "        # output projection\n",
        "    # we need to specify output projection manually, because sampled softmax needs to have access to the the projection matrix \n",
        "    output_projection_w_t = tf.get_variable(\"output_projection_w\", [vocabulary_size, state_size], dtype=DTYPE)\n",
        "    output_projection_w = tf.transpose(output_projection_w_t)\n",
        "    output_projection_b = tf.get_variable(\"output_projection_b\", [vocabulary_size], dtype=DTYPE)\n",
        "    \n",
        "    # define decoder cell\n",
        "    decoder_cell = tf.contrib.rnn.LSTMCell(num_units=state_size)\n",
        "    decoder_cell = DtypeDropoutWrapper(cell=decoder_cell, output_keep_prob=tf_keep_probabiltiy, dtype=DTYPE)\n",
        "    decoder_cell = contrib_rnn.MultiRNNCell(cells=[decoder_cell] * num_lstm_layers, state_is_tuple=True)   \n",
        "    # decoder_cell = contrib_rnn.OutputProjectionWrapper(decoder_cell, output_size=vocabulary_size ) # rnn output: [batch_size, max_time, vocabulary_size ]\n",
        "\n",
        "    # define decoder train netowrk\n",
        "    decoder_outputs_tr, _ , _ = dynamic_rnn_decoder( # decoder outputs, final hidden state, final context state\n",
        "        cell=decoder_cell, # the cell function\n",
        "        decoder_fn= simple_decoder_fn_train(last_encoder_state, name=None),\n",
        "        inputs=decoder_inputs, # [batch_size, max_time, embedding_size].\n",
        "        sequence_length=decoder_sequence_lengths, #  length for sequence in the batch [batch_size] \n",
        "        parallel_iterations=None, # Tradeoff - time for memory\n",
        "        swap_memory=False,\n",
        "        time_major=False)\n",
        "    \n",
        "    # define decoder inference network\n",
        "    decoder_scope.reuse_variables()    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aixz-U_vGuos",
        "colab_type": "text"
      },
      "source": [
        "# Objective and Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8lLfii0Guov",
        "colab_type": "text"
      },
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHlIzEa_Guow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Decoder Output  Shape: [batch_size=%s, max_timesteps=%s, vocabulary_size=%s]\"%tuple(decoder_outputs_tr.shape))\n",
        "#from library.nn_impl import sampled_softmax_loss as dtype_sampled_softmax_loss # imported cutom loss function to support dtype  as a parameter => half precision\n",
        "\n",
        "# reshape outputs of decoders to [ batch_size * max_time , vocabulary_size ]\n",
        "decoder_forward_outputs = tf.reshape(decoder_outputs_tr,[-1, state_size])\n",
        "decoder_target_labels  = tf.reshape(decoder_labels ,[-1, 1])# =>  [ batch_size * max_time ]  sequence of correc tlabel\n",
        "\n",
        "sampled_softmax_losses = tf.nn.sampled_softmax_loss(\n",
        "    weights = output_projection_w_t,# [num_classes, state_size]\n",
        "    biases = output_projection_b, # [num_classes]\n",
        "    inputs = decoder_forward_outputs, #  inputs: A `Tensor` of shape `[batch_size, state_size]`.  The forward activations of the input network. \n",
        "    labels = decoder_target_labels , \n",
        "    num_sampled = num_samples,\n",
        "    num_classes=vocabulary_size,\n",
        "    num_true = 1,\n",
        ")    \n",
        "total_loss_op = tf.reduce_mean(sampled_softmax_losses) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VII0JX4iGuo0",
        "colab_type": "text"
      },
      "source": [
        "## Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJhcsLi2Guo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1_regularizer = tf.contrib.layers.l1_regularizer(\n",
        "    scale=l1_scale, scope=None\n",
        ")\n",
        "weights = tf.trainable_variables()\n",
        "regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, [word_embeddings])\n",
        "\n",
        "regularized_loss = total_loss_op + regularization_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCwv9o2UGuo5",
        "colab_type": "text"
      },
      "source": [
        "## Trainings step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2tuIOv3Guo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get gradients for all trainable parameters with respect to our loss funciton\n",
        "params = tf.trainable_variables()\n",
        "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
        "gradients = tf.gradients(regularized_loss, params)\n",
        "\n",
        "# apply gradient clip\n",
        "clipped_gradients, gradient_norm = tf.clip_by_global_norm(gradients,max_gradient_norm)\n",
        "\n",
        "# Update operation\n",
        "training_step  = optimizer.apply_gradients(zip(clipped_gradients, params), global_step=tf_global_step) # learing rate decay is calulated based on this step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y00bsDaEGuo-",
        "colab_type": "text"
      },
      "source": [
        "# Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teN-PWyRGuo-",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Batch Loading for trainings data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8QEN4NAGuo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load single example from processed file\n",
        "filename_queue = tf.train.string_input_producer([processed_datafile], num_epochs=None) # num_epochs=None \n",
        "reader = tf.TextLineReader()\n",
        "example_id, single_example_logline = reader.read(filename_queue) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1-_iqR5GupD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define how to parse single example (see 1.3)\n",
        "split_example = tf.string_split([single_example_logline],delimiter=\"|\")\n",
        "split_example_dense = tf.sparse_tensor_to_dense(split_example, default_value='', validate_indices=True, name=None)\n",
        "split_example_dense = split_example_dense[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt2hXUjDGupH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split_example_dense[0] is signature id\n",
        "# sequence length\n",
        "sequence_length=tf.string_to_number(split_example_dense[1],out_type=tf.int32)\n",
        "# split encoder inputs\n",
        "enc_split =  tf.string_split([split_example_dense[2]],delimiter=\",\")\n",
        "enc_split_dense = tf.sparse_tensor_to_dense(enc_split, default_value='', validate_indices=True, name=None)\n",
        "x_e_single = tf.string_to_number(enc_split_dense, out_type=tf.int32) \n",
        "# split decoder inputs\n",
        "dec_split =  tf.string_split([split_example_dense[3]],delimiter=\",\")\n",
        "dec_split_dense = tf.sparse_tensor_to_dense(dec_split, default_value='', validate_indices=True, name=None)\n",
        "x_d_single = tf.string_to_number(dec_split_dense, out_type=tf.int32) \n",
        "# split decoder targets\n",
        "tar_split =  tf.string_split([split_example_dense[4]],delimiter=\",\")\n",
        "tar_split_dense = tf.sparse_tensor_to_dense(tar_split, default_value='', validate_indices=True, name=None)\n",
        "y_single = tf.string_to_number(tar_split_dense, out_type=tf.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg319LgsGupL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch the variable length tensor with dynamic padding\n",
        "fetch_trainings_batch = tf.train.batch(\n",
        "    tensors=[\n",
        "        x_e_single[0], #single encoder input line\n",
        "        x_d_single[0], #single decoder input line \n",
        "        y_single[0], #single decoder target line  \n",
        "        sequence_length,   # sequence length of this example\n",
        "    ],\n",
        "    batch_size=batch_size,\n",
        "    dynamic_pad=True,\n",
        "    name=\"trainings_batch\",\n",
        "    allow_smaller_final_batch=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06H23pYJGupT",
        "colab_type": "text"
      },
      "source": [
        "# Session Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxLu0bwKGupV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch_dict(session):\n",
        "    # get trainingsbatch from input queue\n",
        "    batch = session.run([fetch_trainings_batch], feed_dict=None)\n",
        "    batch = batch[0] \n",
        "        \n",
        "    # assign arrays to dictionary\n",
        "    batch_dict = {\n",
        "        x_e:batch[0], # encoder inputs \n",
        "        x_d:batch[1], # decoder inputs\n",
        "        y_d:batch[2], # decoder targets\n",
        "        encoder_sequence_lengths:batch[3], \n",
        "        decoder_sequence_lengths:batch[3]           \n",
        "    }\n",
        "    return batch_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZCQY1_oGupY",
        "colab_type": "text"
      },
      "source": [
        "# Trainings Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqEQd9WtGupZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if learn_model:    \n",
        "    current_epoch = 0\n",
        "    save_checkpoint_after_each_step = int(max_steps/10)\n",
        "    print_loss_after_steps = int(max_steps/100)\n",
        "\n",
        "    queue_capacity = 2 * batch_size\n",
        "\n",
        "    # Saver\n",
        "    saver = tf.train.Saver(tf.global_variables())\n",
        "\n",
        "    # Summaries\n",
        "    tf.summary.scalar(\"total_loss\",tf.cast(total_loss_op, DTYPE)) # summary for accuracy\n",
        "    tf.summary.scalar(\"regularized_loss\",tf.cast(regularized_loss, DTYPE)) # summary for accuracy\n",
        "    # Start session\n",
        "    session = tf.Session()\n",
        "\n",
        "    # Check random seed for reproducability\n",
        "    control_random_number = session.run(tf.random_normal([1])) \n",
        "    print(\"Control Random Number: %0.5f\"%control_random_number) # should change if you modify the graph\n",
        "\n",
        "    \n",
        "    all_summaries = tf.summary.merge_all()\n",
        "    summary_writer = tf.summary.FileWriter(graph_dir, graph=session.graph)\n",
        "\n",
        "    session.run([\n",
        "            tf.local_variables_initializer(),\n",
        "            tf.global_variables_initializer(),\n",
        "        ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EywHJWYOGupc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s= time.time() # start time\n",
        "if learn_model:\n",
        "\n",
        "    word_embeddings_before = session.run(word_embeddings)\n",
        "    import collections\n",
        "    batch_times = collections.deque()\n",
        "\n",
        "\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(sess=session, coord=coord)\n",
        "\n",
        "    for current_step in range(1,max_steps+1): # start from 1 .. max_steps+1 to execute max steps            \n",
        "\n",
        "        try:\n",
        "            step_s = time.time()\n",
        "            # increase step counter\n",
        "            session.run(tf_global_step.assign(current_step)) \n",
        "\n",
        "            # get next batch\n",
        "            batch_dict=get_batch_dict(session)\n",
        "            # execute actions\n",
        "            results = session.run([\n",
        "                total_loss_op, # calculate training loss\n",
        "                regularized_loss, #     \n",
        "                training_step, # calculate gradients, update gradients\n",
        "                all_summaries, # compile summaries and write to graph dir,\n",
        "                learning_rate,\n",
        "                 # get gradients    \n",
        "            ], feed_dict = batch_dict )\n",
        "\n",
        "            summary_writer.add_summary(results[3],current_step)\n",
        "            batch_times.append( (time.time()-step_s))\n",
        "\n",
        "        except Exception as e:\n",
        "            # Report exceptions to the coordinator.\n",
        "            print(\"Aborting trainingsloop :%s\"%str(e.message))\n",
        "            coord.request_stop(e)\n",
        "            break\n",
        "\n",
        "        if current_step % print_loss_after_steps==0:\n",
        "            print(\"Epoch {epoch:02d}, Step {current_step:05d}/{max_steps:05d}, Current Learning rate: {learning_rate:0.4f},  Loss: {loss:0.4f} Regularized Loss: {regularized_loss:0.4f}\".format(\n",
        "                    epoch=int(current_step/(max_steps/epochs)+1), \n",
        "                    current_step=current_step, max_steps=max_steps,\n",
        "                    learning_rate=results[4], \n",
        "                    loss=results[0],regularized_loss=results[1]\n",
        "                )# end format\n",
        "            ) # end print\n",
        "            avg_batch_time =  sum(batch_times) /len(batch_times)\n",
        "            total_time_in_s = avg_batch_time * max_steps\n",
        "            print(\"Average step time: %0.2fs, Estimated total duration: ~%0.2f min (~ %0.2f h) \"% (avg_batch_time, total_time_in_s/60.0, total_time_in_s/3600.0 ))\n",
        "\n",
        "        # save checkpoint every xth step\n",
        "        if current_step % save_checkpoint_after_each_step==0:\n",
        "            print (\"Saving checkpoint\")\n",
        "\n",
        "            chkpoint_out_filename = join_path(checkpoint_path, model_name)\n",
        "            saver.save(session, chkpoint_out_filename , global_step=current_step)             \n",
        "\n",
        "    # stop training queues\n",
        "    coord.request_stop()    \n",
        "    word_embeddings_after = session.run(word_embeddings)\n",
        "    e = time.time()\n",
        "    print(\"Learning took {sec:0.2f} seconds\".format(sec=(e-s)))\n",
        "else:\n",
        "    current_step = 35821 # TODO this needs to be adjusted \n",
        "    \n",
        "    session = tf.Session()\n",
        "    meta_data = join_path(result_dir, checkpoint_path,'rnn-autoencoder-35821.meta') # TODO this needs to be adjusted \n",
        "    print(meta_data)\n",
        "    saver = tf.train.Saver()#tf.train.import_meta_graph(meta_data)\n",
        "    print(\"Restored graph\")\n",
        "    model_to_load  =  tf.train.latest_checkpoint( join_path( result_dir, checkpoint_path))\n",
        "    print(\"Load '%s' from saved checkpoints\"%model_to_load)            \n",
        "    saver.restore(session, model_to_load)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vje5QFQiGupg",
        "colab_type": "text"
      },
      "source": [
        "# Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQD4dwBjGuph",
        "colab_type": "text"
      },
      "source": [
        "# Embedd test loglines 2000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l-Q7iHiGupi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedded_csv = join_path(result_dir, experiment_dir,\"embedded_lines.csv\")\n",
        "embedded_loglines = np.ndarray(shape=[num_examples_to_embed, state_size])\n",
        "\n",
        "if not os.path.exists(embedded_csv):\n",
        "    # load \n",
        "    test_examples = list(open(test_data_processed,\"r\")) \n",
        "    print(len(test_examples))\n",
        "    test_examples = [t.split(\"|\") for t in test_examples]\n",
        "    print(\"Loaded trainingsdata\")\n",
        "\n",
        "    s = time.time()\n",
        "    count = 0\n",
        "    train_batches  =  list(range(0, num_examples_to_embed, batch_size))\n",
        "    print(\"Started embedding %i batches of %i log lines\"%(len(train_batches),num_examples_to_embed ))\n",
        "    for i, ex_id in enumerate(train_batches):\n",
        "        x_e_batch = []\n",
        "        esl_batch = []\n",
        "\n",
        "        incomplete_batch = False # for last batch\n",
        "        incomplete_length = 0\n",
        "        # get batch, write metadata\n",
        "        for b_id, example in enumerate(test_examples[ex_id:ex_id+batch_size]):\n",
        "            count+=1\n",
        "            esl_batch.append(int(example[1])) # sequence length\n",
        "            x_e_batch.append(np.array(example[2].split(\",\"),dtype=np.integer) ) # encoder input\n",
        "            \n",
        "        if len(x_e_batch)<batch_size: # last_batch, so need to zero add id\n",
        "            incomplete_batch=True\n",
        "            incomplete_length = len(x_e_batch)\n",
        "\n",
        "            for _ in range(batch_size-len(x_e_batch)):\n",
        "                esl_batch.append(0)\n",
        "                x_e_batch.append(np.zeros([len(x_e_batch[0])]))\n",
        "\n",
        "        # pad batch\n",
        "        max_seq_len = np.amax(esl_batch) # maximum encoder length\n",
        "        padded_x_e_batch = []\n",
        "        for x_es in x_e_batch:\n",
        "            padded_x_e = np.pad(x_es , (0,max_seq_len-len(x_es)), 'constant', constant_values=0)\n",
        "            padded_x_e_batch.append(padded_x_e)                          \n",
        "\n",
        "        #assign arrays to dictionary\n",
        "        batch_dict = {\n",
        "            x_e:np.array(padded_x_e_batch), # encoder inputs  # [batch_size, max_sequence_length, state_size ]\n",
        "            encoder_sequence_lengths:np.array(esl_batch) # encoder sequence length [batch_size,1]           \n",
        "        }\n",
        "\n",
        "        # execute actions\n",
        "        results = session.run([\n",
        "            last_encoder_state, # get encoded trainings samples\n",
        "        ], feed_dict = batch_dict )\n",
        "\n",
        "        # story in temporary array\n",
        "        if incomplete_batch:\n",
        "            embedded_loglines[ex_id:ex_id+incomplete_length,] = results[0][0].c[0:incomplete_length]\n",
        "        else:\n",
        "            embedded_loglines[ex_id:ex_id+batch_size,] = results[0][0].c # copy c hidden state to tmp_ary\n",
        "\n",
        "\n",
        "    print(\"Embedded %i lines in ~%0.2f min\"%(num_examples_to_embed, ((time.time()-s )/60.0)))\n",
        "    a = np.ndarray((num_examples_to_embed,state_size), dtype=float, buffer=None, offset=0,)\n",
        "    print(\"shape \", a.shape)\n",
        "    print(\"Saved embedded lines to file: %s \"%embedded_csv)\n",
        "    np.savetxt(embedded_csv, a, delimiter=\",\")\n",
        "else:\n",
        "    embedded_loglines = np.genfromtxt(embedded_csv, delimiter=\";\")\n",
        "    print(\"Loaded embedded lines to file: %s \"%embedded_csv)\n",
        "    print(embedded_loglines.shape)\n",
        "\n",
        "X = embedded_loglines\n",
        "for i in X:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNHq-yXKGupm",
        "colab_type": "text"
      },
      "source": [
        "# Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUk8Kzg3BT9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import Birch\n",
        "cluster_alg=\"birch\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kjNjqFXBehJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_true_file = \"/content/gdrive/My Drive/\"+ project_directory + \"/Thaler2017/data/\" + dataset + \".ids\"\n",
        "print(labels_true_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0ZNVhzkBlYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=open(labels_true_file, \"r\")  ###path of the predicted label array consisting text file should be mentioned\n",
        "contents = f.read()\n",
        "f.close()\n",
        "mod_contents = re.findall(r\"[\\w']+\",contents)\n",
        "test_list = [int(i) for i in mod_contents]\n",
        "\n",
        "np.array(list(test_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBhhC1vHBqFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusters = np.array(list(test_list))\n",
        "clusters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FUowbjXPB1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhuaSLP-o1TQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from sklearn.cluster import Birch\n",
        "from sklearn.metrics import homogeneity_completeness_v_measure, silhouette_score, mutual_info_score, adjusted_mutual_info_score\n",
        "import re\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "import scipy.special\n",
        "from itertools import combinations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2nmviu2rnYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getClusters(arr):\n",
        "    clusters = []\n",
        "    c = np.unique(arr)\n",
        "    for i in c:\n",
        "        res_list = list(filter(lambda x: arr[x] == i, range(len(arr))))\n",
        "        clusters += [res_list]\n",
        "    return clusters\n",
        "\n",
        "# def f1Score(trueLabels, predictedLabels):\n",
        "#     true_labels = getClusters(trueLabels)\n",
        "#     predicted_labels = getClusters(predictedLabels)\n",
        "#     dictA = []\n",
        "#     dictB = []\n",
        "#     for i in true_labels:\n",
        "#         comb = combinations(i, 2)\n",
        "#         for j in list(comb):\n",
        "#             dictA.append(list(j))\n",
        "\n",
        "#     for i in predicted_labels:\n",
        "#         comb = combinations(i, 2)\n",
        "#         for j in list(comb):\n",
        "#             dictB.append(list(j))\n",
        "\n",
        "#     a = len([list(x) for x in set(tuple(x) for x in dictA).intersection(set(tuple(x) for x in dictB))])\n",
        "#     b = len([x for x in dictB if x not in dictA])\n",
        "#     c = len([x for x in dictA if x not in dictB])\n",
        "#     f1_score = (2 * a) / ((2 * a) + b + c)\n",
        "#     return f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_U5DqKfVf2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xjQFejUBtU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_thres = 0.1\n",
        "max_thres = 30\n",
        "thres_step = 0.2\n",
        "\n",
        "predicted_labels = {}\n",
        "cluster_results = {}\n",
        "\n",
        "for i in np.arange (min_thres,max_thres,thres_step):\n",
        "  row = []\n",
        "  if (cluster_alg==\"birch\"):\n",
        "    brc = Birch(threshold=i, branching_factor=50, n_clusters=None, compute_labels=True, copy=True)\n",
        "    brc.fit(X)\n",
        "    labels = brc.predict(X)\n",
        "  elif cluster_alg==\"dbscan\":\n",
        "    print(\"dbscan\")\n",
        "    break\n",
        "  \n",
        "  \n",
        "  hom_com_vmes = homogeneity_completeness_v_measure(clusters, labels)\n",
        "  \n",
        "  shilloutte = silhouette_score(X, clusters)\n",
        "  mutualinfoscore = mutual_info_score(clusters, labels, contingency=None)\n",
        "  adjustedmutualinfoscore = adjusted_mutual_info_score(clusters, labels)\n",
        "  # f1_score = f1Score(clusters,labels)\n",
        "  \n",
        "  row+=list(hom_com_vmes)\n",
        "  row.append(shilloutte)\n",
        "  # row.append(f1_score)\n",
        "  row.append(mutualinfoscore)\n",
        "  row.append(adjustedmutualinfoscore)\n",
        "  try:\n",
        "    predicted_labels[i].append(labels)\n",
        "  except KeyError:\n",
        "    predicted_labels[i] = labels\n",
        "  cluster_results[i] = row\n",
        "print(predicted_labels)\n",
        "print(cluster_results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT49NeXuh_Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(cluster_results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QENa06Q4gidk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for p_l in predicted_labels:\n",
        "  print(p_l, len(np.unique(predicted_labels[p_l])), cluster_results[p_l][2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "375NcBVBBuEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "homogenity = []\n",
        "completeness = []\n",
        "vScore = []\n",
        "shilloutte = []\n",
        "f_score = []\n",
        "mutualinfoscore =[]\n",
        "adjustedmutualinfoscore = []\n",
        "\n",
        "y = list(cluster_results.keys())\n",
        "print(\"Threshold : \", list(y))\n",
        "for val in cluster_results.items():\n",
        "  homogenity+=[val[1][0]]\n",
        "  completeness+=[val[1][1]]\n",
        "  vScore+=[val[1][2]]\n",
        "  shilloutte+=[val[1][3]]\n",
        "  # f_score+=[val[1][4]]\n",
        "  mutualinfoscore+=[val[1][4]]\n",
        "  adjustedmutualinfoscore+=[val[1][5]]\n",
        "\n",
        "# print(\"F1 Score : \", f_score)\n",
        "print(\"Homogenity : \", homogenity)\n",
        "print(\"Completeness : \", completeness)\n",
        "print(\"V-Score : \", vScore)\n",
        "print(\"Shilloutte\", shilloutte)\n",
        "print(\"Mutual info score\", mutualinfoscore)\n",
        "print(\"Adjusted mutual info score\", adjustedmutualinfoscore)\n",
        "\n",
        "# plt.plot(y,f_score, label = \"F1 Score\")\n",
        "plt.plot(y,homogenity, label = \"Homogenity\")\n",
        "plt.plot( y,completeness, label = \"Completeness\")\n",
        "plt.plot( y,vScore, label = \"V-Score\")\n",
        "plt.plot(y,shilloutte, label = \"Shilloutte\")\n",
        "plt.plot(y,mutualinfoscore, label = \"Mutual_info_score\")\n",
        "plt.plot(y,adjustedmutualinfoscore, label = \"Adjusted mutual info score\")\n",
        "\n",
        "plt.xlabel('Threshold') \n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show() \n",
        "print(\"Highest V-cscore :\", y[vScore.index(max(vScore))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W7VnFG5FqXc",
        "colab_type": "text"
      },
      "source": [
        "# Write Clustering Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-hJYwaBFp2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustering_Results = {\n",
        "        'Threshold': y,\n",
        "        'Homogenity': homogenity,\n",
        "        'Completeness': completeness,\n",
        "        'vScore': vScore,\n",
        "        'Shilloutte': shilloutte,\n",
        "        'Mutual info score': mutualinfoscore,\n",
        "        'Adjusted mutual info score': adjustedmutualinfoscore\n",
        "    }\n",
        "\n",
        "results = pd.DataFrame(clustering_Results)\n",
        "\n",
        "results.to_csv(join_path(result_dir, experiment_dir, dataset + '_clustering_results.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6icg94zRIeR7",
        "colab_type": "text"
      },
      "source": [
        "# Get template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzoqLROjHuFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getTemplate(candidate):\n",
        "    # candidate: list of list\n",
        "    abstraction = ''\n",
        "\n",
        "    # transpose row to column\n",
        "    candidate_transpose = list(zip(*candidate))\n",
        "    candidate_length = len(candidate)\n",
        "\n",
        "    if candidate_length > 1:\n",
        "        # get abstraction\n",
        "        abstraction_list = []\n",
        "        for index, message in enumerate(candidate_transpose):\n",
        "            message_length = len(set(message))\n",
        "            if message_length == 1:\n",
        "                abstraction_list.append(message[0])\n",
        "            else:\n",
        "                abstraction_list.append('<*>')\n",
        "\n",
        "        abstraction = ' '.join(abstraction_list)\n",
        "\n",
        "    elif candidate_length == 1:\n",
        "        abstraction = ' '.join(candidate[0])\n",
        "\n",
        "    return abstraction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpkXLNr5P1-h",
        "colab_type": "text"
      },
      "source": [
        "# Read Ground ruth templates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqvEv2_pm1aW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_raw_logs = pd.read_csv(\"/content/gdrive/My Drive/\" + project_directory + \"/Datasets_TB/ground_truth/\"+ dataset + \"/\" + dataset +\"_2k.log_structured.csv\") \n",
        "raw_logs = df_raw_logs['Content'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx8xs0Ae7JI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhRjl4pLP_xB",
        "colab_type": "text"
      },
      "source": [
        "# Get best clusterong based config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihaV53PGQbcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(raw_logs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjQPagHOpwPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_labels = predicted_labels[y[vScore.index(max(vScore))]]\n",
        "predicted_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gbu0NenQXQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "groups = pd.DataFrame()\n",
        "groups['predicted_labels'] = predicted_labels\n",
        "groups['raw_logs'] = raw_logs\n",
        "groups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s9Q4akeRkaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in np.unique(groups.predicted_labels):\n",
        "  print(i)\n",
        "  for index,row in groups.iterrows():\n",
        "    if row['predicted_labels'] == i:\n",
        "      print(row['raw_logs'])\n",
        "  print('\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS5IMTebHuD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusters = {}\n",
        "for i in range(0, len(predicted_labels)):\n",
        "    try:\n",
        "        clusters[predicted_labels[i]].append(raw_logs[i].split(\" \"))\n",
        "    except KeyError:\n",
        "        clusters[predicted_labels[i]] = [raw_logs[i].split(\" \")]\n",
        "\n",
        "\n",
        "output = {}\n",
        "for cluster in clusters.items():\n",
        "  template = getTemplate(cluster[1])\n",
        "  output['E' + str(cluster[0])] = template\n",
        "  print(template)\n",
        "  for log in cluster[1]:\n",
        "    print(log)\n",
        "  print('\\n')\n",
        "\n",
        "\n",
        "def writeOutput(output):\n",
        "    line = {\n",
        "        'EventId': list(output.keys()),\n",
        "        'EventTemplate': list(output.values())\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(line)\n",
        "    df.to_csv(join_path(result_dir, experiment_dir, dataset + '_templates.csv'))\n",
        "  \n",
        "  \n",
        "writeOutput(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edto10xfYPEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "structured_log = df_raw_logs.drop(['EventTemplate','EventId'], axis=1)\n",
        "df_eventTemplates = pd.read_csv(join_path(result_dir, experiment_dir, dataset + '_templates.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGEDNfAsN8yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "template = []\n",
        "eventId = []\n",
        " \n",
        "for label in predicted_labels:\n",
        "  template.append(df_eventTemplates[df_eventTemplates['EventId'] == 'E'+str(label)]['EventTemplate']) \n",
        "  eventId.append(df_eventTemplates[df_eventTemplates['EventId'] == 'E'+str(label)]['EventId'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np9ulFVUnTxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "structured_log['EventId'] = eventId\n",
        "structured_log['EventTemplate'] = template"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbGgfAQenbBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "structured_log.to_csv(join_path(result_dir, experiment_dir, dataset + '_structured.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-AlnsJYnhiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(groundtruth, parsedresult):\n",
        "    \n",
        "    df_groundtruth = pd.read_csv(groundtruth)\n",
        "    df_parsedlog = pd.read_csv(parsedresult)\n",
        "\n",
        "    # Remove invalid groundtruth event Templates\n",
        "    null_logids = df_groundtruth[~df_groundtruth['EventTemplate'].isnull()].index\n",
        "    df_groundtruth = df_groundtruth.loc[null_logids]\n",
        "    df_parsedlog = df_parsedlog.loc[null_logids]\n",
        "\n",
        "    (precision, recall, f_measure, accuracy) = get_accuracy(df_groundtruth['EventTemplate'], df_parsedlog['EventTemplate'])\n",
        "    print('Precision: %.4f, Recall: %.4f, F1_measure: %.4f, Parsing_Accuracy: %.4f' % (\n",
        "        precision, recall, f_measure, accuracy))\n",
        "    return f_measure, accuracy\n",
        "\n",
        "\n",
        "def get_accuracy(series_groundtruth, series_parsedlog, debug=False):\n",
        "   \n",
        "    series_groundtruth_valuecounts = series_groundtruth.value_counts()\n",
        "    real_pairs = 0\n",
        "    for count in series_groundtruth_valuecounts:\n",
        "        if count > 1:\n",
        "            real_pairs += scipy.special.comb(count, 2)\n",
        "\n",
        "    series_parsedlog_valuecounts = series_parsedlog.value_counts()\n",
        "    parsed_pairs = 0\n",
        "    for count in series_parsedlog_valuecounts:\n",
        "        if count > 1:\n",
        "            parsed_pairs += scipy.special.comb(count, 2)\n",
        "\n",
        "    accurate_pairs = 0\n",
        "    accurate_events = 0  # determine how many lines are correctly parsed\n",
        "    for parsed_eventId in series_parsedlog_valuecounts.index:\n",
        "        logIds = series_parsedlog[series_parsedlog == parsed_eventId].index\n",
        "        series_groundtruth_logId_valuecounts = series_groundtruth[logIds].value_counts()\n",
        "        error_eventIds = (parsed_eventId, series_groundtruth_logId_valuecounts.index.tolist())\n",
        "        error = True\n",
        "        if series_groundtruth_logId_valuecounts.size == 1:\n",
        "            groundtruth_eventId = series_groundtruth_logId_valuecounts.index[0]\n",
        "            if logIds.size == series_groundtruth[series_groundtruth == groundtruth_eventId].size:\n",
        "                accurate_events += logIds.size\n",
        "                error = False\n",
        "        if error and debug:\n",
        "            print('(parsed_eventId, groundtruth_eventId) =', error_eventIds, 'failed', logIds.size, 'messages')\n",
        "        for count in series_groundtruth_logId_valuecounts:\n",
        "            if count > 1:\n",
        "                accurate_pairs += scipy.special.comb(count, 2)\n",
        "\n",
        "    precision = float(accurate_pairs) / parsed_pairs\n",
        "    recall = float(accurate_pairs) / real_pairs\n",
        "    f_measure = 2 * precision * recall / (precision + recall)\n",
        "    accuracy = float(accurate_events) / series_groundtruth.size\n",
        "    return precision, recall, f_measure, accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5TvjtvqnlWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(evaluate(\"/content/gdrive/My Drive/\" + project_directory + \"/Datasets_TB/ground_truth/\"+ dataset + \"/\" + dataset +\"_2k.log_structured.csv\",    #####path of the structured log csv of the groundtruth\n",
        "               join_path(result_dir, experiment_dir, dataset + '_structured.csv')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uQcEMRwbh93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v91pC3SebL3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r Thaler2017/results/{dataset_number}_{dataset} /content/gdrive/My\\ Drive/{project_directory}/our_experiments/{experiment_type}/{dataset}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}